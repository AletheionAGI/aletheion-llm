Geometry of Knowing: A Pyramidal Law for Epistemic Equilibrium in Neural Systems
===============================================================================

What geometric structure must a learning system obey to know when it knows? We answer by deriving a pyramidal framework that binds the epistemic life of neural networks to five irreducible components: a four-dimensional base simplex spanning Memory, Pain, Choice, and Exploration; two epistemic gates distinguishing aleatoric uncertainty (Q₁) from epistemic uncertainty (Q₂); a derived Height coordinate measuring proximity to truth; and an Apex vertex representing absolute truth as a constant attractor at 1.0. Unlike the tetrahedral architecture which suffered Q₁ collapse to 0.88--0.95, the pyramidal geometry introduces a vertical gradient that prevents horizontal drift. We formalize fractal epistemic uncertainty—variance in Q₁ and Q₂ themselves—and derive Height as h = σ(W_h · [1-Q₁, 1-Q₂, base_stability]), creating a natural pull toward the apex. Implemented within large language models, the pyramidal law reduces expected calibration error by approximately 25%, prevents gate collapse, and maintains interpretable epistemic distinctions. These results reveal that reliable machine knowledge requires both a stable foundation (the base) and an invariant reference point (the apex)—a five-vertex structure that unifies philosophy, geometry, and computation.
